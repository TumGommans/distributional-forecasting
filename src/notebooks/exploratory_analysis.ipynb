{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ac0dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "704c934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_trn = pd.read_csv(\"../../data/X_trn.csv\")\n",
    "y_trn = pd.read_csv(\"../../data/y_trn.csv\")\n",
    "X_test = pd.read_csv(\"../../data/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "538d7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "SEED = 2025\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75d38751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDN hyperparameters\n",
    "N_MIX = 6\n",
    "HIDDEN = 128\n",
    "N_HIDDEN_LAYERS = 2\n",
    "ACTIVATION = nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8475e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "BATCH_SIZE = 256\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 60\n",
    "VAL_FRAC = 0.15\n",
    "CLIP_GRAD = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (31607, 35) (31607,)  Test: (5578, 35)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "\n",
    "def load_and_preprocess():\n",
    "\n",
    "    # Combine to ensure consistent one-hot encoding\n",
    "    all_X = pd.concat([X_trn, X_test], axis=0, ignore_index=True)\n",
    "\n",
    "    cat_cols = [c for c in all_X.columns if all_X[c].dtype == \"object\" or isinstance(all_X[c].dtype, CategoricalDtype)]\n",
    "    num_cols = [c for c in all_X.columns if c not in cat_cols]\n",
    "\n",
    "    if len(cat_cols) > 0:\n",
    "        all_X = pd.get_dummies(all_X, columns=cat_cols, drop_first=False)\n",
    "\n",
    "    # Split data after one-hot encoding\n",
    "    X_trn_enc = all_X.iloc[:len(X_trn)].reset_index(drop=True)\n",
    "    X_test_enc = all_X.iloc[len(X_trn):].reset_index(drop=True)\n",
    "\n",
    "    # Scale numerical data\n",
    "    scaler = StandardScaler()\n",
    "    X_trn_enc[num_cols] = scaler.fit_transform(X_trn_enc[num_cols])\n",
    "    X_test_enc[num_cols] = scaler.transform(X_test_enc[num_cols])\n",
    "\n",
    "    # Transform to numpy arrays\n",
    "    X_trn_np = X_trn_enc.values.astype(np.float32)\n",
    "    y_trn_np = y_trn.values.astype(np.float32).ravel()\n",
    "    X_test_np = X_test_enc.values.astype(np.float32)\n",
    "\n",
    "    return X_trn_np, y_trn_np, X_test_np, scaler\n",
    "\n",
    "X_trn_np, y_trn_np, X_test_np, scaler = load_and_preprocess()\n",
    "print(\"Train:\", X_trn_np.shape, y_trn_np.shape, \" Test:\", X_test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the framework of the MDN model\n",
    "\n",
    "class MDN(nn.Module):\n",
    "    def __init__(self, input_dim, n_mixtures=N_MIX, hidden=HIDDEN, n_layers=N_HIDDEN_LAYERS):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last = input_dim\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(nn.Linear(last, hidden))\n",
    "            layers.append(ACTIVATION())\n",
    "            last = hidden\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.logits = nn.Linear(last, n_mixtures)   # mixture weights\n",
    "        self.means = nn.Linear(last, n_mixtures)    # means\n",
    "        self.logvars = nn.Linear(last, n_mixtures)  # log variances\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.net(x)\n",
    "        return self.logits(h), self.means(h), self.logvars(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02029af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MDN log-likelihood (negative since pytorch minimalizes)\n",
    "def mdn_nll(y, logits, means, logvars, eps=1e-8):\n",
    "    \n",
    "    # Set the right dimensions of the Tensor \n",
    "    if y.dim() == 1:\n",
    "        y = y.unsqueeze(1)\n",
    "\n",
    "    \n",
    "    log_weights = torch.log_softmax(logits, dim=1)\n",
    "    var = torch.exp(logvars) + eps\n",
    "    y_exp = y.expand_as(means)\n",
    "    sq = (y_exp - means) ** 2\n",
    "    comp_logprob = -0.5 * (torch.log(2 * torch.pi * var) + sq / var)\n",
    "    log_prob = torch.logsumexp(log_weights + comp_logprob, dim=1)\n",
    "    return -log_prob.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
